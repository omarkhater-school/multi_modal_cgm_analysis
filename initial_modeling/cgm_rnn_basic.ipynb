{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "def datacsv2dl(img,cgm,viome,lbl):\n",
    "    class dataset(Dataset):\n",
    "        def __init__(self, data, labels):\n",
    "            self.data = data\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            d = torch.tensor(self.data.iloc[idx][self.data.columns.difference(['Subject ID','Day'])])\n",
    "            label = torch.tensor(self.labels.iloc[idx][self.labels.difference(['Subject ID','Day'])], dtype=torch.int32)\n",
    "            return d, label\n",
    "    \n",
    "    img_data = pd.read_csv(img)\n",
    "    img_data['Image Before Breakfast'] = img_data['Image Before Breakfast'].apply(ast.literal_eval).apply(np.array)\n",
    "    img_data['Image Before Lunch'] = img_data['Image Before Lunch'].apply(ast.literal_eval).apply(np.array)\n",
    "\n",
    "    cgm_data = pd.read_csv(cgm)\n",
    "    cgm_data['Breakfast Time'] = pd.to_datetime(cgm_data['Breakfast Time'], errors='coerce')\n",
    "    cgm_data['Lunch Time'] = pd.to_datetime(cgm_data['Lunch Time'], errors='coerce')\n",
    "    cgm_data['CGM Data'] = cgm_data['CGM Data'].apply(ast.literal_eval)\n",
    "    for _, row in cgm_data.iterrows():\n",
    "        for i, t in enumerate(row['CGM Data']):\n",
    "            row['CGM Data'][i] = (datetime.strptime(t[0], '%Y-%m-%d %H:%M:%S').timestamp(), t[1:])\n",
    "\n",
    "    viome_data = pd.read_csv(viome)\n",
    "    viome_data['Viome'] = viome_data['Viome'].apply(ast.literal_eval).apply(np.array)\n",
    "\n",
    "    data = img_data.merge(cgm_data, on=['Subject ID','Day'])\n",
    "    data = data.merge(viome_data, on=['Subject ID'])\n",
    "\n",
    "    labels = pd.read_csv(lbl)\n",
    "    if lbl[-8:]=='only.csv':\n",
    "        labels = data.merge(labels, on=['Subject ID','Day'])[['Breakfast Calories','Breakfast Carbs','Breakfast Fat','Breakfast Protein']]\n",
    "    else:\n",
    "        labels = data.merge(labels, on=['Subject ID','Day'])[['Breakfast Calories','Lunch Calories','Breakfast Carbs','Lunch Carbs','Breakfast Fat','Lunch Fat','Breakfast Protein','Lunch Protein']]\n",
    "    \n",
    "    ds = dataset(data,labels)\n",
    "    return DataLoader(ds, batch_size=32, shuffle=True)\n",
    "\n",
    "def HM(dt):\n",
    "    return dt.hour * 60 + dt.minute\n",
    "\n",
    "def datacsv2ndarry_cgm(cgm,viome,lbl):\n",
    "    # img_data = pd.read_csv(img)\n",
    "    # img_data['Image Before Breakfast'] = img_data['Image Before Breakfast'].apply(ast.literal_eval).apply(np.array)\n",
    "    # img_data['Image Before Lunch'] = img_data['Image Before Lunch'].apply(ast.literal_eval).apply(np.array)\n",
    "\n",
    "    cgm_data = pd.read_csv(cgm)\n",
    "    cgm_data['Breakfast Time'] = pd.to_datetime(cgm_data['Breakfast Time'], errors='coerce').apply(HM)\n",
    "    cgm_data['Lunch Time'] = pd.to_datetime(cgm_data['Lunch Time'], errors='coerce').apply(HM)\n",
    "    cgm_data['CGM Data'] = cgm_data['CGM Data'].apply(ast.literal_eval)\n",
    "    cgm_data.dropna(subset=['Breakfast Time','Lunch Time','CGM Data'],inplace=True)\n",
    "    for j, row in cgm_data.iterrows():\n",
    "        if cgm_data.at[j, 'CGM Data']==[]:\n",
    "            cgm_data.drop(j, inplace=True)\n",
    "            continue\n",
    "        # print(j)\n",
    "        # try:\n",
    "        # cgm_data.at[j, 'Breakfast Time'] = HM(row['Breakfast Time'])\n",
    "        # cgm_data.at[j, 'Lunch Time'] = HM(row['Lunch Time'])\n",
    "        for i, t in enumerate(row['CGM Data']):\n",
    "            row['CGM Data'][i] = [HM(datetime.strptime(t[0], '%Y-%m-%d %H:%M:%S')), t[1]]\n",
    "        # except:\n",
    "        #     cgm_data.drop(j, inplace=True)\n",
    "\n",
    "    viome_data = pd.read_csv(viome)\n",
    "    # viome_data['Viome'] = viome_data['Viome'].apply(ast.literal_eval).apply(np.array)\n",
    "\n",
    "    data = cgm_data.merge(viome_data, on=['Subject ID'])\n",
    "\n",
    "    labels = pd.read_csv(lbl)\n",
    "    if lbl[-8:]=='only.csv':\n",
    "        labels = data.merge(labels, on=['Subject ID','Day'])[['Breakfast Calories','Breakfast Carbs','Breakfast Fat','Breakfast Protein']]\n",
    "        labels = labels[['Breakfast Calories','Breakfast Carbs']]\n",
    "        print(f'Label Columns: {labels.columns}')\n",
    "    else:\n",
    "        labels = data.merge(labels, on=['Subject ID','Day'])[['Breakfast Calories','Lunch Calories','Breakfast Carbs','Lunch Carbs','Breakfast Fat','Lunch Fat','Breakfast Protein','Lunch Protein']]\n",
    "        labels = labels[['Breakfast Calories','Lunch Calories','Breakfast Carbs','Lunch Carbs']]\n",
    "        print(f'Label Columns: {labels.columns}')\n",
    "    data = data[['Breakfast Time','Lunch Time','CGM Data','Diabetes Status','A1C']]\n",
    "    print(f'Data Columns: {data.columns}')\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Label Columns: Index(['Breakfast Calories', 'Lunch Calories', 'Breakfast Carbs',\n",
      "       'Lunch Carbs'],\n",
      "      dtype='object')\n",
      "Data Columns: Index(['Breakfast Time', 'Lunch Time', 'CGM Data', 'Diabetes Status', 'A1C'], dtype='object')\n",
      "\n",
      "Testing Set:\n",
      "Label Columns: Index(['Breakfast Calories', 'Breakfast Carbs'], dtype='object')\n",
      "Data Columns: Index(['Breakfast Time', 'Lunch Time', 'CGM Data', 'Diabetes Status', 'A1C'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# train_loader = datacsv2dl('data/img_train.csv','data/cgm_train.csv','data/demo_viome_train.csv','data/label_train.csv')\n",
    "# test_loader = datacsv2dl('data/img_test.csv','data/cgm_test.csv','data/demo_viome_test.csv','data/label_test_breakfast_only.csv')\n",
    "\n",
    "print('Training Set:')\n",
    "X,Y = datacsv2ndarry_cgm('data/cgm_train.csv','data/demo_viome_train.csv','data/label_train.csv')\n",
    "print('\\nTesting Set:')\n",
    "Xt,Yt = datacsv2ndarry_cgm('data/cgm_test.csv','data/demo_viome_test.csv','data/label_test_breakfast_only.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,Xv,Y,Yv = train_test_split(X,Y,train_size=0.8,random_state=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 5), (56, 5), (224, 4), (56, 4))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Xv.shape, Y.shape, Yv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[458.0, 722.0,\n",
       "        list([[460, 138.55333333333334], [465, 153.19333333333333], [470, 172.46666666666667], [475, 193.28666666666666], [480, 217.38], [485, 243.56], [490, 263.73333333333335], [495, 271.0], [500, 270.7266666666667], [505, 267.81333333333333], [510, 258.44666666666666], [515, 246.81333333333333], [520, 239.08666666666667], [525, 231.81333333333333], [530, 223.81333333333333], [535, 216.90666666666667], [540, 214.54666666666665], [545, 217.36666666666667], [550, 222.09333333333333], [555, 225.82], [560, 228.82], [565, 234.00666666666666], [570, 245.28], [575, 256.46], [580, 264.3666666666667], [585, 269.3666666666667], [590, 273.5466666666667], [595, 274.7266666666667], [600, 274.2733333333333], [605, 275.0], [610, 273.9066666666667], [615, 269.6333333333333], [620, 262.72], [625, 249.9], [630, 236.54], [635, 228.63333333333333], [640, 225.27333333333334], [645, 224.36], [650, 217.26666666666668], [655, 206.99333333333334], [660, 197.08666666666667], [665, 190.36], [670, 185.18], [675, 182.45333333333335], [680, 180.18], [685, 176.63333333333333], [690, 171.08666666666667], [695, 164.36], [700, 164.36], [705, 153.90666666666667], [710, 149.90666666666667], [715, 146.45333333333335], [720, 145.54666666666665], [725, 150.55333333333334], [730, 162.73333333333332], [735, 175.19333333333333], [740, 192.28], [745, 201.27333333333334], [750, 201.18], [755, 196.26666666666668], [760, 186.54], [765, 176.99333333333334], [770, 168.45333333333335], [775, 167.54666666666665], [780, 170.91333333333333], [785, 176.82], [790, 177.90666666666667], [795, 174.72666666666666], [800, 175.64], [805, 181.64], [810, 185.72666666666666], [815, 189.92], [820, 208.46666666666667], [825, 221.90666666666667], [830, 215.72], [835, 206.72666666666666], [840, 206.0], [845, 204.36], [850, 202.18666666666667], [855, 210.73333333333332], [860, 222.37333333333333], [865, 236.18666666666667], [870, 243.64], [875, 249.64], [880, 255.64], [885, 260.82], [890, 263.82], [895, 266.82], [900, 269.2733333333333], [905, 269.18], [910, 266.7266666666667], [915, 265.7266666666667], [920, 264.7266666666667], [925, 263.4533333333333], [930, 260.6333333333333], [935, 255.08666666666667], [940, 248.08666666666667], [945, 248.08666666666667]]),\n",
       "        3, 6.9],\n",
       "       [647.0, 792.0,\n",
       "        list([[635, 93.21333333333334], [640, 95.82], [645, 103.06666666666666], [650, 113.67333333333333], [655, 124.06666666666666], [660, 134.06666666666666], [665, 142.85333333333332], [670, 156.92], [675, 170.06666666666666], [680, 174.60666666666665], [685, 175.60666666666665], [690, 176.60666666666665], [695, 183.06666666666666], [700, 185.78666666666666], [705, 175.29333333333332], [710, 168.39333333333335], [715, 158.29333333333332], [720, 142.29333333333332], [725, 129.32666666666665], [730, 123.18], [735, 126.24666666666667], [740, 135.67333333333335], [745, 148.49333333333334], [750, 155.82], [755, 158.82], [760, 162.42666666666668], [765, 162.78666666666666], [770, 157.14666666666668], [775, 153.39333333333335], [780, 152.39333333333335], [785, 151.39333333333335], [790, 149.78666666666666], [795, 141.11333333333334], [800, 128.72], [805, 120.36], [810, 118.60666666666667], [815, 121.42666666666666], [820, 123.60666666666667], [825, 124.0], [830, 122.78666666666666], [835, 120.78666666666666], [840, 120.0], [845, 120.60666666666667], [850, 121.0], [855, 122.21333333333334], [860, 123.60666666666667], [865, 123.39333333333333], [870, 121.18], [875, 118.18], [880, 114.57333333333334], [885, 109.36], [890, 104.57333333333334], [895, 104.82], [900, 106.60666666666667], [905, 107.60666666666667], [910, 108.60666666666667], [915, 107.78666666666666], [920, 106.39333333333333], [925, 105.39333333333333], [930, 103.18], [935, 97.75333333333333], [940, 91.96666666666667], [945, 89.39333333333333], [950, 91.42666666666666], [955, 96.03333333333333], [960, 99.21333333333334], [965, 102.42666666666666], [970, 108.24666666666667], [975, 112.21333333333334], [980, 116.64], [985, 119.0], [990, 122.03333333333333], [995, 123.39333333333333], [1000, 121.78666666666666], [1005, 118.57333333333334], [1010, 113.96666666666667], [1015, 113.96666666666667]]),\n",
       "        1, 5.4],\n",
       "       [318.0, 636.0,\n",
       "        list([[290, 146.27666666666667], [295, 146.0], [300, 146.72333333333333], [305, 148.44666666666666], [310, 149.0], [315, 152.61666666666667], [320, 160.51], [325, 165.89333333333335], [330, 167.0], [335, 164.83], [340, 161.83], [345, 163.89333333333335], [350, 171.51], [355, 181.23333333333335], [360, 191.95666666666668], [365, 200.78666666666666], [370, 207.34], [375, 213.34], [380, 219.34], [385, 223.89333333333335], [390, 227.17], [395, 230.89333333333335], [400, 229.10666666666665], [405, 221.49], [410, 215.38333333333333], [415, 209.66], [420, 206.55333333333334], [425, 207.44666666666666], [430, 210.89333333333335], [435, 214.17], [440, 217.89333333333335], [445, 221.89333333333335], [450, 223.72333333333333], [455, 224.72333333333333], [460, 225.0], [465, 224.27666666666667], [470, 221.83], [475, 216.66], [480, 215.0], [485, 211.40728476821192], [490, 208.55704697986576], [495, 202.21333333333334], [500, 190.59666666666666], [505, 178.32], [510, 168.49], [515, 160.93666666666667], [520, 155.38333333333333], [525, 150.38333333333333], [530, 150.38333333333333], [630, 115.17], [635, 118.89333333333333], [640, 121.44666666666667], [645, 124.89333333333333], [650, 133.95666666666668], [655, 147.85], [660, 164.29666666666668], [665, 184.91333333333333], [670, 203.29666666666668], [675, 216.68], [680, 225.78666666666666], [685, 236.68], [690, 245.78666666666666], [695, 253.06333333333333], [700, 256.44666666666666], [705, 245.42666666666668], [710, 235.21333333333334], [715, 222.15], [720, 216.55333333333334], [725, 216.0], [730, 217.44666666666666], [735, 221.61666666666667], [740, 226.61666666666667], [745, 230.17], [750, 232.44666666666666], [755, 233.0], [760, 232.27666666666667], [765, 232.0], [770, 231.27666666666667], [775, 228.10666666666665], [780, 219.76666666666665], [785, 212.66], [790, 205.21333333333334], [795, 199.38333333333333], [800, 195.10666666666665], [805, 193.27666666666667], [810, 192.27666666666667], [815, 192.0], [820, 193.44666666666666], [825, 193.27666666666667], [830, 190.83], [835, 186.38333333333333], [840, 181.38333333333333], [845, 177.10666666666665], [850, 168.76666666666665], [855, 160.21333333333334], [860, 154.38333333333333], [865, 150.10666666666665], [870, 150.10666666666665]]),\n",
       "        2, 6.4],\n",
       "       ...,\n",
       "       [506.0, 954.0,\n",
       "        list([[490, 111.29333333333334], [495, 114.02666666666667], [500, 121.32], [505, 130.02666666666667], [510, 137.46666666666667], [515, 146.73333333333332], [520, 151.58666666666667], [525, 156.17333333333335], [530, 164.02666666666667], [535, 169.85333333333332], [540, 167.82666666666665], [545, 160.26666666666668], [550, 157.32], [555, 164.56], [560, 161.12], [565, 155.12], [570, 148.82666666666665], [575, 141.26666666666668], [580, 136.56], [585, 134.14666666666668], [590, 135.0], [595, 134.70666666666668], [600, 132.56], [605, 129.26666666666668], [610, 124.70666666666666], [615, 122.41333333333333], [620, 119.29333333333334], [625, 120.56], [630, 117.70666666666666], [635, 115.70666666666666], [640, 113.85333333333334], [645, 112.85333333333334], [650, 112.0], [655, 112.0], [660, 112.14666666666666], [665, 113.0], [670, 113.0], [675, 112.85333333333334], [680, 111.85333333333334], [685, 110.70666666666666], [690, 108.41333333333333], [695, 104.56], [700, 101.85333333333334], [705, 100.70666666666666], [710, 99.0], [715, 99.44], [720, 102.73333333333333], [725, 108.61333333333333], [730, 108.61333333333333], [945, 132.53333333333333], [950, 123.41333333333333], [955, 119.56], [960, 117.0], [965, 116.85333333333334], [970, 115.70666666666666], [975, 113.41333333333333], [980, 109.26666666666667], [985, 104.70666666666666], [990, 102.70666666666666], [995, 101.29333333333334], [1000, 103.44], [1005, 106.29333333333334], [1010, 107.70666666666666], [1015, 106.0], [1020, 105.70666666666666], [1025, 103.85333333333334], [1030, 103.73333333333333], [1035, 108.29333333333334], [1040, 109.70666666666666], [1045, 107.85333333333334], [1050, 106.85333333333334], [1055, 106.0], [1060, 106.14666666666666], [1065, 107.44], [1070, 109.85333333333334], [1075, 109.29333333333334], [1080, 111.14666666666666], [1085, 112.73333333333333], [1090, 117.88], [1095, 123.73333333333333], [1100, 129.32], [1105, 138.76], [1110, 150.46666666666667], [1115, 159.29333333333332], [1120, 159.68], [1125, 150.68], [1130, 142.12], [1135, 136.12], [1140, 129.82666666666665], [1145, 122.12], [1150, 116.85333333333334], [1155, 116.29333333333334], [1160, 118.58666666666667], [1165, 123.17333333333333], [1170, 131.02666666666667], [1175, 138.02666666666667], [1180, 144.88], [1185, 150.44]]),\n",
       "        1, 5.5],\n",
       "       [560.0, 754.0,\n",
       "        list([[550, 120.11666666666666], [555, 121.30666666666667], [560, 119.42333333333333], [565, 121.27], [570, 125.11666666666666], [575, 128.42333333333335], [580, 132.81], [585, 140.96333333333334], [590, 143.73], [595, 137.76666666666668], [600, 129.46], [605, 126.0], [610, 125.57666666666667], [615, 123.73], [620, 119.46], [625, 115.57666666666667], [630, 117.96333333333334], [635, 124.54], [640, 126.30666666666667], [645, 122.73], [650, 121.84666666666666], [655, 123.42333333333333], [660, 124.84666666666666], [665, 125.15333333333334], [670, 123.15333333333334], [675, 122.42333333333333], [680, 125.11666666666666], [685, 134.77333333333334], [690, 145.27], [695, 145.73], [700, 144.0], [705, 146.54], [710, 152.96333333333334], [715, 157.42333333333335], [720, 158.42333333333335], [725, 153.49666666666667], [730, 144.73], [735, 140.03666666666666], [740, 133.03666666666666], [745, 131.11666666666667], [750, 133.57666666666665], [755, 136.81], [760, 144.11666666666667], [765, 147.84666666666666], [770, 145.61333333333334], [775, 133.38], [780, 119.61333333333333], [785, 112.88333333333334], [790, 110.42333333333333], [795, 112.27], [800, 114.0], [805, 110.61333333333333], [810, 104.30666666666667], [815, 102.0], [820, 103.27], [825, 106.27], [830, 109.27], [835, 111.42333333333333], [840, 111.57666666666667], [845, 110.57666666666667], [850, 110.84666666666666], [855, 111.57666666666667], [860, 109.30666666666667], [865, 106.57666666666667], [870, 105.15333333333334], [875, 102.30666666666667], [880, 101.69333333333333], [885, 106.54], [890, 111.27], [895, 113.42333333333333], [900, 114.84666666666666], [905, 113.88333333333334], [910, 108.03666666666666], [915, 105.69333333333333], [920, 109.27], [925, 108.88333333333334], [930, 104.30666666666667], [935, 102.84666666666666], [940, 104.84666666666666], [945, 106.0], [950, 107.27], [955, 110.69333333333333], [960, 116.38666666666667], [965, 123.54], [970, 125.73], [975, 123.57666666666667], [980, 121.30666666666667], [985, 121.30666666666667]]),\n",
       "        2, 5.9],\n",
       "       [466.0, 725.0,\n",
       "        list([[450, 113.08], [455, 114.24], [460, 117.56], [465, 124.96], [470, 136.8], [475, 146.48], [480, 152.64], [485, 160.56], [490, 167.16], [495, 169.0], [500, 169.08], [505, 169.6], [510, 164.36], [515, 156.76], [520, 154.08], [525, 155.0], [530, 155.24], [535, 158.4], [540, 162.92], [545, 161.92], [550, 161.0], [555, 160.68], [560, 156.76], [565, 153.92], [570, 152.76], [575, 149.92], [580, 149.0], [585, 148.92], [590, 147.92], [595, 146.76], [600, 143.76], [605, 140.84], [610, 138.52], [615, 132.52], [620, 126.28], [625, 117.52], [630, 111.68], [635, 107.76], [640, 104.84], [645, 102.92], [650, 101.84], [655, 100.0], [660, 100.0], [665, 100.08], [670, 101.0], [675, 101.08], [680, 102.08], [685, 103.16], [690, 105.08], [715, 114.08], [720, 114.92], [725, 114.0], [730, 114.48], [735, 120.72], [740, 130.2], [745, 145.12], [750, 158.96], [755, 170.4], [760, 175.24], [765, 177.68], [770, 173.6], [775, 168.6], [780, 163.68], [785, 159.76], [790, 156.92], [795, 155.92], [800, 154.76], [805, 151.76], [810, 148.92], [815, 147.76], [820, 144.84], [825, 142.84], [830, 140.84], [835, 138.76], [840, 135.68], [845, 132.0], [850, 131.84], [855, 130.0], [860, 130.0], [865, 129.92], [870, 128.84], [875, 127.08], [880, 128.0], [885, 127.84], [890, 125.84], [895, 124.0], [900, 124.08], [905, 125.08], [910, 126.24], [915, 129.08], [920, 130.08], [925, 130.92], [930, 129.92], [935, 128.92], [940, 127.92], [945, 126.84], [950, 125.0], [955, 125.0]]),\n",
       "        2, 5.7]], dtype=object)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "# Custom Dataset\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.target = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]\n",
    "        if not row[2]:\n",
    "            raise ValueError(f\"Sequence at index {idx} is empty.\")\n",
    "        seq = torch.tensor(row[2], dtype=torch.float32)\n",
    "        aux = torch.tensor([row[0], row[1], row[3], row[4]], dtype=torch.float32)\n",
    "        target = torch.tensor(self.target[idx], dtype=torch.float32)\n",
    "        return seq, aux, target\n",
    "\n",
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    sequences, aux_data, targets = zip(*batch)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0.0)\n",
    "    aux_data = torch.stack(aux_data)\n",
    "    targets = torch.stack(targets)\n",
    "    return padded_sequences, lengths, aux_data, targets\n",
    "\n",
    "\n",
    "dataset = TimeSeriesDataset(X,Y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 5), (224, 4))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset.data.shape, dataloader.dataset.target.shape\n",
    "# dataloader.dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class RNNWithAuxiliary(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, aux_dim, output_dim):\n",
    "        super(RNNWithAuxiliary, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.aux_dense = nn.Linear(aux_dim, 16)\n",
    "        self.fc = nn.Linear(hidden_dim + 16, output_dim)\n",
    "\n",
    "    def forward(self, sequences, lengths, aux_data):\n",
    "        # Pack sequences for LSTM\n",
    "        packed_sequences = pack_padded_sequence(sequences, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, _) = self.lstm(packed_sequences)\n",
    "        lstm_output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        lstm_output = hidden[-1]  # Take the last hidden state\n",
    "        \n",
    "        # Process auxiliary data\n",
    "        aux_output = torch.relu(self.aux_dense(aux_data))\n",
    "        \n",
    "        # Concatenate LSTM output and auxiliary data\n",
    "        combined = torch.cat((lstm_output, aux_output), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 214078.0938\n",
      "Epoch 2, Loss: 203165.0625\n",
      "Epoch 3, Loss: 192598.9844\n",
      "Epoch 4, Loss: 182244.7031\n",
      "Epoch 5, Loss: 171984.5000\n",
      "Epoch 6, Loss: 161714.6875\n",
      "Epoch 7, Loss: 151289.8750\n",
      "Epoch 8, Loss: 140831.7656\n",
      "Epoch 9, Loss: 130411.5938\n",
      "Epoch 10, Loss: 120071.8672\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "input_dim = 2  # Each time step has 2 features\n",
    "hidden_dim = 32\n",
    "aux_dim = 4  # Auxiliary features\n",
    "output_dim = 4  # Single output\n",
    "model = RNNWithAuxiliary(input_dim, hidden_dim, aux_dim, output_dim)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    for sequences, lengths, aux_data, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths, aux_data)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
